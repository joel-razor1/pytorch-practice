{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "transform =transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5)),])\n",
    "\n",
    "trainset=datasets.MNIST('~/.pytorch/MNIST_data/',download=True, train=True, transform=transform )\n",
    "trainloader=torch.utils.data.DataLoader(trainset,batch_size=64,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.2881, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "model=nn.Sequential(nn.Linear(784,128), nn.ReLU(),nn.Linear(128,64),nn.ReLU(),nn.Linear(64,10))\n",
    "criterion=nn.CrossEntropyLoss()\n",
    "images,labels=next(iter(trainloader))\n",
    "images=images.view(images.shape[0],-1)\n",
    "\n",
    "logits=model(images)\n",
    "loss=criterion(logits,labels)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.2759, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "#USING  SOFTMAX FUNCTION\n",
    "\n",
    "model=nn.Sequential(nn.Linear(784,128),nn.ReLU(),nn.Linear(128,64),nn.ReLU(),nn.Linear(64,10),nn.LogSoftmax(dim=1))\n",
    "criterion=nn.NLLLoss()\n",
    "\n",
    "images,labels=next(iter(trainloader))\n",
    "\n",
    "images=images.view(images.shape[0],-1)\n",
    "logps=model(images)\n",
    "loss=criterion(logps,labels)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.2547, -0.3463],\n",
      "        [ 0.4361,  0.1283]], requires_grad=True)\n",
      "tensor([[0.0649, 0.1200],\n",
      "        [0.1902, 0.0165]], grad_fn=<PowBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#Showing the working of Autograd. This is used for backpropagation\n",
    "\n",
    "x=torch.randn(2,2,requires_grad=True)\n",
    "print(x)\n",
    "\n",
    "y=x**2\n",
    "print(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PowBackward0 object at 0x0000014D2C8D5588>\n"
     ]
    }
   ],
   "source": [
    "print(y.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0979, grad_fn=<MeanBackward1>)\n"
     ]
    }
   ],
   "source": [
    "z=y.mean()\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "z.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1273, -0.1732],\n",
      "        [ 0.2181,  0.0642]])\n"
     ]
    }
   ],
   "source": [
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1273, -0.1732],\n",
      "        [ 0.2181,  0.0642]], grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(x/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Coming back to the the main problem. Using the Autograd with loss function\n",
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128, 64),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(64, 10),\n",
    "                      nn.LogSoftmax(dim=1))\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "images, labels = next(iter(trainloader))\n",
    "images = images.view(images.shape[0], -1)\n",
    "\n",
    "logps = model(images)\n",
    "loss = criterion(logps, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before backward pass: \n",
      " None\n",
      "After backward pass: \n",
      " tensor([[ 0.0008,  0.0008,  0.0008,  ...,  0.0008,  0.0008,  0.0008],\n",
      "        [-0.0011, -0.0011, -0.0011,  ..., -0.0011, -0.0011, -0.0011],\n",
      "        [-0.0007, -0.0007, -0.0007,  ..., -0.0007, -0.0007, -0.0007],\n",
      "        ...,\n",
      "        [-0.0009, -0.0009, -0.0009,  ..., -0.0009, -0.0009, -0.0009],\n",
      "        [ 0.0013,  0.0013,  0.0013,  ...,  0.0013,  0.0013,  0.0013],\n",
      "        [-0.0012, -0.0012, -0.0012,  ..., -0.0012, -0.0012, -0.0012]])\n"
     ]
    }
   ],
   "source": [
    "print('Before backward pass: \\n', model[0].weight.grad)\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "print('After backward pass: \\n', model[0].weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial weights -  Parameter containing:\n",
      "tensor([[-0.0318,  0.0133,  0.0107,  ..., -0.0036, -0.0129, -0.0067],\n",
      "        [-0.0024,  0.0043, -0.0033,  ..., -0.0275, -0.0031,  0.0228],\n",
      "        [-0.0161, -0.0357, -0.0008,  ...,  0.0012,  0.0326,  0.0132],\n",
      "        ...,\n",
      "        [-0.0302, -0.0339,  0.0238,  ...,  0.0055,  0.0139, -0.0169],\n",
      "        [-0.0324,  0.0083,  0.0223,  ...,  0.0145,  0.0241,  0.0334],\n",
      "        [ 0.0323,  0.0339,  0.0260,  ..., -0.0005,  0.0088, -0.0299]],\n",
      "       requires_grad=True)\n",
      "Gradient - tensor([[ 0.0019,  0.0019,  0.0019,  ...,  0.0019,  0.0019,  0.0019],\n",
      "        [-0.0004, -0.0004, -0.0004,  ..., -0.0004, -0.0004, -0.0004],\n",
      "        [-0.0005, -0.0005, -0.0005,  ..., -0.0005, -0.0005, -0.0005],\n",
      "        ...,\n",
      "        [ 0.0021,  0.0021,  0.0021,  ...,  0.0021,  0.0021,  0.0021],\n",
      "        [ 0.0030,  0.0030,  0.0030,  ...,  0.0030,  0.0030,  0.0030],\n",
      "        [ 0.0018,  0.0018,  0.0018,  ...,  0.0018,  0.0018,  0.0018]])\n"
     ]
    }
   ],
   "source": [
    "print('Initial weights - ', model[0].weight)\n",
    "\n",
    "images, labels = next(iter(trainloader))\n",
    "images.resize_(64, 784)\n",
    "\n",
    "\n",
    "optimizer.zero_grad()\n",
    "\n",
    "\n",
    "output = model(images)\n",
    "loss = criterion(output, labels)\n",
    "loss.backward()\n",
    "print('Gradient -', model[0].weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated weights -  Parameter containing:\n",
      "tensor([[-0.0318,  0.0133,  0.0107,  ..., -0.0036, -0.0129, -0.0067],\n",
      "        [-0.0024,  0.0043, -0.0033,  ..., -0.0275, -0.0031,  0.0228],\n",
      "        [-0.0161, -0.0357, -0.0008,  ...,  0.0012,  0.0326,  0.0132],\n",
      "        ...,\n",
      "        [-0.0302, -0.0339,  0.0238,  ...,  0.0055,  0.0139, -0.0169],\n",
      "        [-0.0324,  0.0082,  0.0223,  ...,  0.0145,  0.0240,  0.0334],\n",
      "        [ 0.0323,  0.0339,  0.0259,  ..., -0.0005,  0.0088, -0.0299]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "optimizer.step()\n",
    "print('Updated weights - ', model[0].weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.9208926347527169\n",
      "Training loss: 0.8347641978817962\n",
      "Training loss: 0.5039233458575918\n",
      "Training loss: 0.416378460411451\n",
      "Training loss: 0.37570927271456606\n"
     ]
    }
   ],
   "source": [
    "##Now training the same algorithm in a loop\n",
    "\n",
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128, 64),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(64, 10),\n",
    "                      nn.LogSoftmax(dim=1))\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.003)\n",
    "\n",
    "epochs = 5\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, labels in trainloader:\n",
    "        images = images.view(images.shape[0], -1)\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(images)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    else:\n",
    "        print(f\"Training loss: {running_loss/len(trainloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_classify(img, ps, version=\"MNIST\"):\n",
    "    ''' Function for viewing an image and it's predicted classes.\n",
    "    '''\n",
    "    ps = ps.data.numpy().squeeze()\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(figsize=(6,9), ncols=2)\n",
    "    ax1.imshow(img.resize_(1, 28, 28).numpy().squeeze())\n",
    "    ax1.axis('off')\n",
    "    ax2.barh(np.arange(10), ps)\n",
    "    ax2.set_aspect(0.1)\n",
    "    ax2.set_yticks(np.arange(10))\n",
    "    if version == \"MNIST\":\n",
    "        ax2.set_yticklabels(np.arange(10))\n",
    "    elif version == \"Fashion\":\n",
    "        ax2.set_yticklabels(['T-shirt/top',\n",
    "                            'Trouser',\n",
    "                            'Pullover',\n",
    "                            'Dress',\n",
    "                            'Coat',\n",
    "                            'Sandal',\n",
    "                            'Shirt',\n",
    "                            'Sneaker',\n",
    "                            'Bag',\n",
    "                            'Ankle Boot'], size='small');\n",
    "    ax2.set_title('Class Probability')\n",
    "    ax2.set_xlim(0, 1.1)\n",
    "\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import helper\n",
    "\n",
    "images, labels = next(iter(trainloader))\n",
    "\n",
    "img = images[0].view(1, 784)\n",
    "# Turn off gradients to speed up this part\n",
    "with torch.no_grad():\n",
    "    logps = model(img)\n",
    "\n",
    "# Output of the network are log-probabilities, need to take exponential for probabilities\n",
    "ps = torch.exp(logps)\n",
    "view_classify(img.view(1, 28, 28), ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
